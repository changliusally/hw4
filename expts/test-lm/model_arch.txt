===============================================================================================
Layer (type:depth-idx)                        Output Shape              Param #
===============================================================================================
DecoderOnlyTransformer                        [256, 260, 35]            --
├─Embedding: 1-1                              [256, 260, 256]           8,960
├─PositionalEncoding: 1-2                     [256, 260, 256]           --
├─Dropout: 1-3                                [256, 260, 256]           --
├─ModuleList: 1-4                             --                        --
│    └─SelfAttentionDecoderLayer: 2-1         [256, 260, 256]           --
│    │    └─SelfAttentionLayer: 3-1           [256, 260, 256]           263,680
│    │    └─FeedForwardLayer: 3-2             [256, 260, 256]           526,080
│    └─SelfAttentionDecoderLayer: 2-2         [256, 260, 256]           --
│    │    └─SelfAttentionLayer: 3-3           [256, 260, 256]           263,680
│    │    └─FeedForwardLayer: 3-4             [256, 260, 256]           526,080
├─LayerNorm: 1-5                              [256, 260, 256]           512
├─Linear: 1-6                                 [256, 260, 35]            8,995
===============================================================================================
Total params: 1,597,987
Trainable params: 1,597,987
Non-trainable params: 0
Total mult-adds (Units.MEGABYTES): 274.87
===============================================================================================
Input size (MB): 0.53
Forward/backward pass size (MB): 2744.93
Params size (MB): 4.29
Estimated Total Size (MB): 2749.76
===============================================================================================